# AI Internal Support Engineer

## Overview
AI Internal Support Engineer is a backend-first Retrieval-Augmented Generation (RAG) system that enables employees to ask natural language questions about internal company documents and receive accurate, grounded answers with source citations.

The system is designed to **avoid hallucinations**, enforce **role-based access control**, and explicitly respond with *“I don’t know”* when the requested information is not present in the uploaded documents.

This project focuses on correctness, auditability, and production-oriented AI system design rather than UI polish.

---

## Problem Statement
Early-stage startups and growing teams rely heavily on internal documentation such as deployment guides, engineering runbooks, and operational policies. As documentation grows, finding accurate answers becomes time-consuming and error-prone.

Naive AI chatbots often hallucinate answers or leak information across teams, which makes them unsafe for internal use.

---

## Solution
This project implements a **strict RAG pipeline** where:
- Only relevant document chunks are retrieved.
- The LLM is allowed to answer **only from retrieved context**.
- Every answer includes source citations.
- Missing information results in an explicit refusal to answer.

The system behaves more like an internal knowledge engine than a generic chatbot.

---

## Key Guarantees
- No hallucinations
- Explicit “I don’t know” responses
- Source citations for every answer
- Role-based document access
- Backend-controlled grounding logic

---

## Architecture
Document Upload
↓
Text Extraction
↓
Chunking
↓
Embedding (sentence-transformers)
↓
FAISS Vector Store
↓
Semantic Retrieval
↓
LLM Answer Generation (Groq)
↓
Grounded Answer + Citations

---

## Tech Stack

### Backend
- FastAPI (Python)
- JWT Authentication
- Pydantic schemas

### Retrieval & AI
- sentence-transformers (embeddings)
- FAISS (vector similarity search)
- Groq API (LLaMA models)

### Storage
- Local filesystem for documents
- FAISS index for embeddings

### Tooling
- Swagger/OpenAPI for API testing
- Python virtual environment

---

## Core Features

### Document Ingestion
- Supports PDF, Markdown, and text files
- Automatic chunking for semantic retrieval
- Metadata tagging for role-based access

### Semantic Search
- FAISS-based vector similarity search
- Retrieval scoped by user role
- Returns only relevant document chunks

### Answer Generation
- Strict system prompt enforcement
- Answers generated only from retrieved context
- Explicit fallback when information is missing

### Security
- JWT-based authentication
- Role-based access control
- No cross-role document leakage

---

## Example Behavior

**Question:**  
What is the rollback strategy?

**Answer:**  
The system automatically rolls back to the previous stable release if deployment fails.

**Sources:**  
- deployment.txt

---

**Question:**  
What database does the system use?

**Answer:**  
I don’t have enough information in the provided documents.

**Sources:**  
None

---

## API Endpoints

### Authentication
- `POST /auth/login` – User login and token generation

### Documents
- `POST /documents/upload` – Upload and ingest documents
- `POST /documents/search` – Semantic document search

### Chat
- `POST /chat/ask` – Ask questions using RAG

### Health
- `GET /health` – Service health check

---

## Design Decisions

- Retrieval is enforced **before** generation to prevent hallucination.
- The LLM never sees the full document corpus.
- Citations are attached by the backend, not generated by the model.
- The system is model-agnostic and can switch LLM providers without architectural changes.

---

## Limitations
- Single-node FAISS (not distributed)
- No streaming responses
- No frontend UI (API-first design)

---

## Future Improvements
- Distributed vector store (e.g., Milvus or Pinecone)
- Streaming responses
- Frontend dashboard for non-technical users
- Fine-grained document section citations
- Multi-tenant organization support

---

## License
MIT
